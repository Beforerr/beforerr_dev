{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Utils for Polars\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import polars as pl\n",
    "from typing import Any, Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_to_pd_dataframe(\n",
    "    df: pl.DataFrame | pl.LazyFrame, # original DataFrame or LazyFrame\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert a Polars DataFrame or LazyFrame into a pandas-like DataFrame.\n",
    "    \"\"\"\n",
    "    if isinstance(df, pl.LazyFrame):\n",
    "        df = df.collect()\n",
    "    elif not isinstance(df, pl.DataFrame):\n",
    "        raise TypeError(\"Input must be a Polars DataFrame or LazyFrame\")\n",
    "\n",
    "    data = df.to_pandas(use_pyarrow_extension_array=True)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sort(df: pl.DataFrame, col=\"time\"):\n",
    "    if df.get_column(col).is_sorted():\n",
    "        return df.set_sorted(col)\n",
    "    else:\n",
    "        return df.sort(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _expand_selectors(items: Any, *more_items: Any) -> list[Any]:\n",
    "    \"\"\"\n",
    "    See `_expand_selectors` in `polars`.\n",
    "    \"\"\"\n",
    "    expanded: list[Any] = []\n",
    "    for item in (\n",
    "        *(\n",
    "            items\n",
    "            if isinstance(items, Collection) and not isinstance(items, str)\n",
    "            else [items]\n",
    "        ),\n",
    "        *more_items,\n",
    "    ):\n",
    "        expanded.append(item)\n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def pl_norm(columns, *more_columns) -> pl.Expr:\n",
    "    \"\"\"\n",
    "    Computes the square root of the sum of squares for the given columns.\n",
    "\n",
    "    Args:\n",
    "    *columns (str): Names of the columns.\n",
    "\n",
    "    Returns:\n",
    "    pl.Expr: Expression representing the square root of the sum of squares.\n",
    "    \"\"\"\n",
    "    all_columns = _expand_selectors(columns, *more_columns)\n",
    "    squares = [pl.col(column).pow(2) for column in all_columns]\n",
    "\n",
    "    return sum(squares).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def decompose_vector(\n",
    "    df: pl.DataFrame, vector_col, name=None, suffixes: list = [\"_x\", \"_y\", \"_z\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Decompose a vector column in a DataFrame into separate columns for each component with custom suffixes.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pl.DataFrame): The input DataFrame.\n",
    "    - vector_col (str): The name of the vector column to decompose.\n",
    "    - name (str, optional): Base name for the decomposed columns. If None, uses `vector_col` as the base name.\n",
    "    - suffixes (list, optional): A list of suffixes to use for the decomposed columns.\n",
    "      If None or not enough suffixes are provided, defaults to '_0', '_1', etc.\n",
    "\n",
    "    Returns:\n",
    "    - pl.DataFrame: A DataFrame with the original vector column decomposed into separate columns.\n",
    "    \"\"\"\n",
    "\n",
    "    if name is None:\n",
    "        name = vector_col\n",
    "\n",
    "    # Determine the maximum length of vectors in the column to handle dynamic vector lengths\n",
    "    max_length = df.select(pl.col(vector_col).list.len()).max()[0, 0]\n",
    "\n",
    "    if suffixes is None or len(suffixes) < max_length:\n",
    "        if suffixes is None:\n",
    "            suffixes = []\n",
    "        # Extend or create the list of suffixes with default values\n",
    "        suffixes.extend([f\"_{i}\" for i in range(len(suffixes), max_length)])\n",
    "\n",
    "    # Create column expressions for each element in the vector\n",
    "    column_expressions = [\n",
    "        pl.col(vector_col).list.get(i).alias(name).name.suffix(suffixes[i])\n",
    "        for i in range(max_length)\n",
    "    ]\n",
    "\n",
    "    return df.with_columns(column_expressions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast filter for a list of predicates\n",
    "\n",
    "[Use a list of filters within polars - Stack Overflow](https://stackoverflow.com/questions/74993391/use-a-list-of-filters-within-polars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def filter_series_by_ranges_i(data: pl.Series, starts: list, stops: list):\n",
    "    starts_index = data.search_sorted(starts)\n",
    "    ends_index = data.search_sorted(stops, side=\"right\")\n",
    "\n",
    "    return pl.concat(\n",
    "        pl.arange(*range, eager=True) for range in zip(starts_index, ends_index)\n",
    "    ).unique()\n",
    "\n",
    "\n",
    "def filter_df_by_ranges(data: pl.DataFrame, starts: list, stops: list, col=\"time\"):\n",
    "    \"\"\"\n",
    "    Filter a DataFrame from ranges\n",
    "    \"\"\"\n",
    "\n",
    "    indices_unique = filter_series_by_ranges_i(data[col], starts, stops)\n",
    "    return data[indices_unique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def _filter_series_by_ranges_i(data: pl.Series, starts: list, stops: list):\n",
    "    return pl.concat(data.is_between(*range) for range in zip(starts, stops))\n",
    "\n",
    "\n",
    "def _filter_df_by_intervals(data: pl.DataFrame, starts: list, stops: list, col=\"time\"):\n",
    "    \"\"\"\n",
    "    Filter a DataFrame based on intervals defined by start and stop times.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pl.DataFrame): The DataFrame to be filtered.\n",
    "    - starts (list): A list of start times for the intervals.\n",
    "    - stops (list): A list of stop times for the intervals.\n",
    "\n",
    "    Returns:\n",
    "    - pl.DataFrame: The filtered DataFrame containing rows within the specified intervals.\n",
    "    \"\"\"\n",
    "    predicates = pl.any_horizontal(\n",
    "        pl.col(col).is_between(*range) for range in zip(starts, stops)\n",
    "    )\n",
    "\n",
    "    return data.filter(predicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data():\n",
    "    return pl.DataFrame({\n",
    "        \"time\": pl.arange(10),\n",
    "    })\n",
    "\n",
    "def test_filter_df_by_intervals(sample_data):\n",
    "    filtered_data = filter_df_by_ranges(sample_data, [1, 5], [3, 7])\n",
    "    assert len(filtered_data) == 6\n",
    "    assert filtered_data[\"time\"].min() == 1\n",
    "    assert filtered_data[\"time\"].max() == 7\n",
    "\n",
    "def test_filter_df_by_intervals_no_match(sample_data):\n",
    "    filtered_data = filter_df_by_ranges(sample_data, [100, 200], [300, 400])\n",
    "    assert len(filtered_data) == 0\n",
    "\n",
    "def test_filter_df_by_intervals_edge_case(sample_data):\n",
    "    filtered_data = filter_df_by_ranges(sample_data, [1, 1], [1, 1])\n",
    "    assert len(filtered_data) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_sample_data = sample_data()\n",
    "test_filter_df_by_intervals(_sample_data)\n",
    "test_filter_df_by_intervals_no_match(_sample_data)\n",
    "test_filter_df_by_intervals_edge_case(_sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.1 ms, sys: 8.89 ms, total: 47 ms\n",
      "Wall time: 45.6 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (999_801, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>time</th></tr><tr><td>i64</td></tr></thead><tbody><tr><td>0</td></tr><tr><td>1</td></tr><tr><td>2</td></tr><tr><td>3</td></tr><tr><td>4</td></tr><tr><td>&hellip;</td></tr><tr><td>999796</td></tr><tr><td>999797</td></tr><tr><td>999798</td></tr><tr><td>999799</td></tr><tr><td>999800</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (999_801, 1)\n",
       "┌────────┐\n",
       "│ time   │\n",
       "│ ---    │\n",
       "│ i64    │\n",
       "╞════════╡\n",
       "│ 0      │\n",
       "│ 1      │\n",
       "│ 2      │\n",
       "│ 3      │\n",
       "│ 4      │\n",
       "│ …      │\n",
       "│ 999796 │\n",
       "│ 999797 │\n",
       "│ 999798 │\n",
       "│ 999799 │\n",
       "│ 999800 │\n",
       "└────────┘"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000000\n",
    "data = pl.DataFrame({\n",
    "    \"time\": np.arange(n),\n",
    "})\n",
    "\n",
    "starts = list(range(0, n-200, 100))\n",
    "stops = list(range(100, n-100, 100))\n",
    "\n",
    "%time filter_df_by_ranges(data, starts, stops)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
